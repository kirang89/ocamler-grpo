export BASE_MODEL_ID=Qwen/Qwen2.5-Coder-1.5B-Instruct
export TRAINING_DATASET=kiranpg/ocaml-training-problems

export GRPO_NUM_GENERATIONS=8
export GRPO_BATCH_SIZE=2
export GRPO_GRAD_ACCUM_STEPS=4
export GRPO_TEMPERATURE=1.0
export GRPO_MAX_PROMPT=800
export GRPO_MAX_COMPLETION=700
export GRPO_LEARNING_RATE=5e-6
export GRPO_BETA=0.01
export GRPO_TOP_ENTROPY_QUANTILE=0.9
export GRPO_DISABLE_PROSE_PENALTY=false

export TOKENIZERS_PARALLELISM=true
export REWARD_POOL_SIZE=10
export PYTHONUNBUFFERED=1
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export TERM=xterm-256color

# SFT Configuration (optimized for A40 48GB with 1.5B model)
export SFT_DATASET=kiranpg/ocaml-sft-problems
export SFT_OUTPUT_DIR=sft_runs

# Batch settings: effective batch = 8 * 4 = 32
# A40 can handle batch_size=8 easily for 1.5B model with 1024 seq length
# Increase to 16 if VRAM usage stays under 40GB
export SFT_BATCH_SIZE=8
export SFT_GRAD_ACCUM_STEPS=4

# Learning rate: 2e-5 is standard for SFT, can try 1e-5 if loss spikes
export SFT_LEARNING_RATE=2e-5
export SFT_NUM_EPOCHS=3
export SFT_MAX_SEQ_LENGTH=1024

# Logging and checkpointing
export SFT_LOGGING_STEPS=10
export SFT_SAVE_STEPS=200
export SFT_SAVE_TOTAL_LIMIT=5

# Optimizer and scheduler settings
export SFT_LR_SCHEDULER_TYPE=cosine
export SFT_WARMUP_RATIO=0.03
export SFT_WEIGHT_DECAY=0.01
export SFT_MAX_GRAD_NORM=1.0
export SFT_OPTIMIZER=adamw_8bit
export SFT_DATALOADER_NUM_WORKERS=2

# LoRA settings: higher rank for A40's VRAM headroom
export LORA_R=64
export LORA_ALPHA=128
export LORA_DROPOUT=0.05

export SFT_PUSH_TO_HUB=true
export SFT_HUB_MODEL_ID="kiranpg/qwen2.5-ocamler-sft"g
